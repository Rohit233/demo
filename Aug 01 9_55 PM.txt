#PR 1

x=5;
y=5;
sum = addition (x,y);
sub = substraction(x,y);
mul = multiplication(x,y);
div = division(x,y);


#addition.m
function add = addition(x,y)
 add = x+y ;
display(add);
end

#substraction.m
function sub = substraction(x,y)
sub = x-y;
display(sub);
end

#multiplication.m
function mul = multiplication(x,y)
mul = x*y;
display(mul);
end

#division.m
function div=  division(x,y)
div=x/y;
display(div);
end

_____________________________________________________________________________________________________________
# AND || OR (PR-2)
xOR = [0 0 1 1;0 1 0 1];
tOR = [0 1 1 1];

xAND = [0 0 1 1;0 1 0 1];
tAND = [0 0 0 1];


netOR = perceptron;
netAND = perceptron;
netOR = train(netOR,xOR,tOR);
netAND = train(netAND,xAND,tAND);
testOR1 = [1;1];
testOR2 = [0;1];
testOR3 = [0;0];
yOR1 = netOR(testOR1)
yOR2 = netOR(testOR2)
yOR3 = netOR(testOR3)

testAND1 = [1;1];
testAND2 = [0;1];
testAND3 = [0;0];

yAND1 = netAND(testAND1)
yAND2 = netAND(testAND2)
yAND3 = netAND(testAND3)
______________________________________________________________________________________________________________________________________
# LINEARLY SEPARABLE (PR-3)

x= [1.4, 1.5, 2.5, 3.4, 1.9,2.2; 8, 12, 14, 15, 19, 24];
T = [0 0 1 1 1 1];
net = perceptron;
figure(1)
plotpv(x,T)
net = train(net,x,T);

plotpc(net.IW{1}, net.b{1})

___________________________________________________________________________________________________________________________________

# LINEARLY NON SEPARABLE (PR-4)

https://in.mathworks.com/help/deeplearning/ug/linearly-non-separable-vectors.html
X = [ -0.5 -0.5 +0.3 -0.1 -0.8;
      -0.5 +0.5 -0.5 +1.0 +0.0 ];
T = [1 1 0 0 0];


net = perceptron;
plotpv(X,T);
net = configure(net,X,T);

hold on
plotpv(X,T);
linehandle = plotpc(net.IW{1},net.b{1});

for a = 1:25
   [net,Y,E] = adapt(net,X,T);
   linehandle = plotpc(net.IW{1},net.b{1},linehandle);  drawnow;
end
________________________________________________________________________________________________________________

# CRAB CLASSIFICATION (PR-5)

https://in.mathworks.com/help/deeplearning/examples.html?category=pattern-recognition-and-classification&s_tid=CRUX_topnav

[x,t] = crab_dataset;
size(x)
size(t)
setdemorandstream(491218382)

net = patternnet(10);
%view(net)

[net,tr] = train(net,x,t);  

plotperform(tr)

testX = x(:,tr.testInd);
testT = t(:,tr.testInd);

testY = net(testX);
testIndices = vec2ind(testY)

%plotconfusion(testT,testY)

[c,cm] = confusion(testT,testY)

fprintf('Percentage Correct Classification   : %f%%\n', 100*(1-c));

fprintf('Percentage Incorrect Classification : %f%%\n', 100*c);

%plotroc(testT,testY)

view(net)

__________________________________________________________________________________________________________________________________________

# WINE CLASSIFICATION (PR-6)
https://in.mathworks.com/help/deeplearning/examples.html?category=pattern-recognition-and-classification&s_tid=CRUX_topnav

[x,t] = wine_dataset;
size(x)
size(t)

net = feedforwardnet(10);
[net,tr] = train(net,x,t);
plotperform(tr)

testX = x(:,tr.testInd);
testT = t(:,tr.testInd);

testY = net(testX);
testIndices = vec2ind(testY)
[c,cm] = confusion(testT,testY)
fprintf('Percentage Correct Classification   : %f%%\n', 100*(1-c));
fprintf('Percentage Incorrect Classification : %f%%\n', 100*c);
__________________________________________________________________________________________________________________________________________-
# K-means clustering (PR-7)

import math

x = [1,3,6,7,6,8,9,2,4,4,3,2,1,5,6]
y = [1,2,1,3,4,2,6,7,8,4,6,3,2,5,2]

# plt.show()

c1 = [6,1]
c2 = [8,2]

centroid1 = []
centroid2 = []

list1 = []
list2 = []

distanceListFromC1 = []
distanceListFromC2 = []



while True:


# finding distance between data-points and center
  for i in range(0,len(x)):
      distanceListFromC1.append(math.dist((x[i], y[i]), c1))
  for i in range(0,len(x)):
      distanceListFromC2.append(math.dist((x[i], y[i]), c2))

#assigning data points to centroids based on distance
  for i in range(0,len(distanceListFromC1)):
    if (distanceListFromC1[i] <= distanceListFromC2[i]):
        list1.append([x[i], y[i]])
    else:
        list2.append([x[i], y[i]])

    # print(list1)
    # print(list2)

# calculating mean of x for c1
  c1mean_x = 0
  for i in list1:
     c1mean_x += i[0]
  c1mean_x /= len(list1)
    # print(c1mean_x)

    # calculating mean of y for c1
  c1mean_y = 0
  for i in list1:
       c1mean_y += i[-1]
    # print(c1mean_y)

  c1mean_y /= len(list1)
    # print(c1mean_y)
    
  centroid1 = [c1mean_x, c1mean_y]
    # print(centroid1)

# calculating mean of x for c2
  c2mean_x = 0
  for i in list2:
        c2mean_x += i[0]

  c2mean_x /= len(list2)
    # print(c2mean_x)

# calculating mean of y for c2
  c2mean_y = 0
  for i in list2:
        c2mean_y += i[-1]
    # print(c2mean_y)

  c2mean_y /= len(list2)
    # print(c2mean_y)

  centroid2 = [c2mean_x, c2mean_y]
    # print(centroid2)

#checking if previous centroids match with new centroids
  if c1 == centroid1 and c2 == centroid2:
        break
  else:
        c1 = centroid1
        c2 = centroid2
        list1 = []
        list2 = []
        distanceListFromC1 = []
        distanceListFromC2 = []

print("After k-means clustering adjusted centroids are:")
print(c1)
print(c2)




_____________________________________________________________________________________________________________________________________
# CHARACTER RECOGNITION (PR-8)

https://in.mathworks.com/help/deeplearning/examples.html?category=pattern-recognition-and-classification&s_tid=CRUX_topnav

[X,T] = prprob;
plotchar(X(:,1))
setdemorandstream(pi);
net1 = feedforwardnet(25);
view(net1)
net1.divideFcn = '';
net1 = train(net1,X,T,nnMATLAB);
numNoise = 30;
Xn = min(max(repmat(X,1,numNoise)+randn(35,26*numNoise)*0.2,0),1);
Tn = repmat(T,1,numNoise);
figure
plotchar(Xn(:,1))
net2 = feedforwardnet(25);
net2 = train(net2,Xn,Tn,nnMATLAB);
noiseLevels = 0:.05:1;
numLevels = length(noiseLevels);
percError1 = zeros(1,numLevels);
percError2 = zeros(1,numLevels);
for i = 1:numLevels
  Xtest = min(max(repmat(X,1,numNoise)+randn(35,26*numNoise)*noiseLevels(i),0),1);
  Y1 = net1(Xtest);
  percError1(i) = sum(sum(abs(Tn-compet(Y1))))/(26*numNoise*2);
  Y2 = net2(Xtest);
  percError2(i) = sum(sum(abs(Tn-compet(Y2))))/(26*numNoise*2);
end
figure
plot(noiseLevels,percError1*100,'--',noiseLevels,percError2*100);
title('Percentage of Recognition Errors');
xlabel('Noise Level');
ylabel('Errors');
legend('Network 1','Network 2','Location','NorthWest')

_________________________________________________________________________________________________________________________________
